---
layout: post
title:  "Thomas Nagel"
author: "accumulation-vector"
---

I don't know what got me onto this but I have been thinking about this for a minute. This post represents a mostly hate fueled rant against Thomas Nagel and his thoughts on consciousness. He is one of the easiest to hate people to ever write on philosophy of the mind. I guess the thing is there are more people that hate him than those that take him seriously, so I'm not sure that I'm adding a lot to what has been said before. 

His argument point comes up pretty heavily in people who trot out all manner of qualia based arguments surrounding AI and consciousness. Which is really annoying to me, especially as people often don't go further in these arguments than maintaining that qualia exists or some other form of base argument that never goes far.

It is pretty easy without even getting into his arguments to see where everything went wrong just from his background. He did his undergraduate degree at Cornell University and got his PhD in philosophy from Harvard with John Rawls as his advisor. Following Rawls, his main areas of philosophical expertise are ethics and political theory, which he takes a very Rawlsian stance on both topics. Which in my opinion is some of the worst political theory I have ever read in my entire life. 

So even coming at this knowing nothing about him aside from his background it is very easy to dislike him and his body of work right off the bat. He is primarily known for his critiques of reductionism, though the majority of his work has been in the field of ethical theories of altruism. One could say he is a one-hit wonder for his essay on the mind, though this was really a one-off work that is from what I have seen largely disconnected from the rest of his body of work.

His main body of work is on altruism and consists of a formulation of what he called ‘altruistic action’. From what I've been able to gather on this he believes that we can characterize different types of 'goodness' in actions based on both genuine reasons and subjective reasons. He goes on to try to claim that a genuine reason is one that should be applicable widely to anyone as a kind of moral truth and that when our subjective reasons can apply to anyone we are acting impersonally toward some good. The intent behind this argument is to classify different intents into categories. 

I didn't actually read any of his work on this subject because quite frankly it seems like a ridiculous re-application of Kantian categorical imperatives as philosophers like to do. I've seen a million examples of this, but it never ceases to amaze me just how many philosophers make entire careers out of rephrasing Kant and Hegel with contemporary terms.

All of this is an aside before jumping into my thoughts on his famous work 'What It Is Like To Be A Bat?'. Spoilers for anyone that has never read the paper before, but he does not ever state what it is like to be a bat sadly. I'll start by summarizing what I believe Nagel's argument is.

Nagel begins the text by theorizing that reductionist theories of the mind-body problem as it relates to consciousness are mostly incorrect and formulated not in order to better explain consciousness but instead to justify reductionist views. In Nagel’s view, the subjective character of experience is what it is like to be that organism from its own conscious perspective. In this section, he is very carefully sidestepping issues that people might bring against his paper by creating his own terms and defining them his own way rather than using terms from the field. This is the first signal to anyone reading that something very off is going on here.

He then goes on to articulate that even if we could take on the characteristics of an animal such as a bat and slowly transform ourselves into a bat given bat-like features, we would still not be experiencing bat-ness. Instead, we are a human with bat features, which is not really related to the phenomenological experience of what it is like the be a bat. He argues that we cannot ever truly understand the phenomenological experiences of the bat or other alien forms of life without some new form of understanding. 

Put another way, we can say that my thoughts would be human thoughts filtered through bat-like sensory experiences. My neurons are not formed around an existence of having only echolocation, if I were to somehow place myself in this kind of phenomenological situation I could not experience it the same way that a bat does. 

Similarly, I cannot degrade my intelligence down to that of a bat's intelligence and then come back again this is not really realistic. In order for me to experience what it is like to be a bat, I need to become fully indistinguishable from that of a bat, and at that point I am no longer capable of having human phenomenological experiences. To put it bluntly, there is always an information loss when we try to experience something so vastly different than ourselves, there is loss in the analogy that is created to communicate from bat-like experiences into human communicable knowledge of those experiences.

To function properly, Nagel argues that any reductionist program has to be based on an analysis of the things which are going to be reduced. If the reductionist model does not account for conscious experience it is not properly formed. To him, the physical basis of the mind has to account for the specific phenomenological differences in experience between different minds. 

He goes on to claim that we cannot ever describe within our own language or symbols the phenomenology of other minds different from our own. Even with regard to our ability to describe our own minds, he states that we would probably not be able to get an accurate description of our own phenomenology through our linguistic compression if our minds weren’t already basically the same from person to person. By this he means the less similar I am to another person's mind the less likely I am to understand their phenomenological descriptions of their subjective experience.

Next, he discusses how we can move to develop objective models of various things. Our models commonly have components that Nagel argues we can separate out, things that are measurable by things other than the human body, and things that are intrinsic to the human experience of a given object. 

He argues that if we want an objective view of a specific object the best thing we can hope to do is move as far away from our human descriptive experience of that object as possible to be more ‘objective’. The example he gives is potentially using some outside apparatus in order to create objective facts about the world around us that are not centralized within the human experience. 

In the text, the main example he gives is lightening as a human experience and lightening as experienced by some kind of device which measures some aspect of the physical phenomena. In this way, he argues that we can build up sets of facts that transcend the experiences of individuals. 

Near the end of the text, he argues that we could potentially form some kind of new way to communicate experiences but does not go into what this would look like. This could potentially be linguistic or through some technological advance which would allow us to experience the consciousness of another being through an apparatus connecting the two. He does not however give any picture of what this might actually materially look like.
