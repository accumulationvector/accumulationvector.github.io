---
layout: post
title:  "The Nagelian Implications of Brain Interfaces"
author: "accumulation-vector"
---


I don't know what got me onto this but I have been thinking about this for a minute, because it surprisingly comes up a lot. This post represents a mostly hate fueled rant against Thomas Nagel and his thoughts on consciousness. He is one of the easiest to hate people to ever write on philosophy of the mind. I guess the thing is there are more people that hate him than those that take him seriously, so I'm not sure that I'm adding a lot to what has been said before. He is exceedingly tricky to argue against in that he is clearly both wrong and correct in various conflicting ways. Which makes for a very annoying read.

The points of his argument come up pretty heavily in people who trot out all manner of qualia based arguments surrounding AI and consciousness. Which is really annoying to me, especially as people often don't go further in these arguments than maintaining that qualia exists or some other form of base argument that never goes far.

This is maybe a silly thing to say, but we can see hints of what the issues are just by looking at his academcic background, without even examining the arguments themselves. He did his undergraduate degree at Cornell University and got his PhD in philosophy from Harvard with John Rawls as his advisor. Following Rawls, his main areas of philosophical expertise are ethics and political theory, which he takes a very Rawlsian stance on both topics. Which in my opinion, Rawls is some of the worst political and ethical theory I have ever read in my entire life. 

So even coming at this knowing nothing about him aside from his background it is very easy to dislike him and his body of work right off the bat. He is primarily known for his singular critique of reductionism in the essay I'm going to discuss here. Interestingly, the majority of his work has been in the field of ethical theories of altruism. One could say he is a one-hit wonder for his essay on the mind, though this was really a one-off work that is (as far as I'm aware) largely disconnected from the rest of his body of thought. I flipped through a single book of his called 'Mortal Questions' which contains the famous bat essay. The majority of his work seems totally centered around moral and ethical issues in various work, and not in a way that I could see as being particularly novel or worth engaging with.

His main body of work is on altruism and consists of a formulation of what he called ‘altruistic action’. From what I've been able to gather on this he believes that we can characterize different types of 'goodness' in actions based on both genuine reasons and subjective reasons. He goes on to try to claim that a genuine reason is one that should be applicable widely to anyone as a kind of moral truth and that when our subjective reasons can apply to anyone we are acting impersonally toward some good. The intent behind this argument is to classify different intents into categories. 

I didn't actually read any of his work on this subject because quite frankly it seems like a ridiculous re-application of Kantian categorical imperatives as philosophers often do. I've seen a million examples of this, but it never ceases to amaze me just how many philosophers make entire careers out of rephrasing Kant and Hegel with contemporary terms. Resurrecting Kant has been out of style for 40 years, I guess when he was writing his main body of work this was in vogue at the time. At present, I think most reasonable people would view this moral and ethical worlk as old fashioned.

All of this is an aside before jumping into my thoughts on his core work 'What It Is Like To Be A Bat?'. Spoilers for anyone that has never read the paper before, but he does not ever give an answer to what it is like to be a bat sadly. I'll start by summarizing what I believe Nagel's argument is.

Nagel begins the text by theorizing that reductionist theories of the mind-body problem as it relates to consciousness are mostly incorrect and formulated not in order to better explain consciousness but instead to justify reductionist views. In Nagel’s view, the subjective character of experience is what it is like to be that organism from its own conscious perspective. In this section, he is very carefully sidestepping issues that people might bring against his paper by creating his own terms and defining them his own way rather than using terms from the field. 

A careful reader will notice that his definitions of 'consciousness' and 'experience' are very unlike what most people would probably characterize them as but this is often done in a very subtle way. The quite mysterious phrase "subjective character of experience" is invented by him as a weird placeholder for his alternative definitions in an odd way (note that this phrasing and definitional strucutre only exists within Nagel's work). This is the first signal to anyone reading that something very off is going on here.

He then goes on to articulate that even if we could take on the characteristics of an animal such as a bat and slowly transform ourselves into a bat given bat-like features, we would still not be experiencing bat-ness. Instead, we are a human with bat features, which is not really related to the phenomenological experience of what it is like to be a bat. He argues that we cannot ever truly understand the phenomenological experiences of the bat or other alien forms of life without some new form of understanding. 

Put another way, we can say that my thoughts would be human thoughts filtered through bat-like sensory experiences. My neurons are not formed around an existence of having only echolocation, if I were to somehow place myself in this kind of phenomenological situation I still could not experience it the same way that a bat does. 

Similarly, I cannot degrade my intelligence down to that of a bat's intelligence and then come back again to my regular level of intelligence. This is not really possible or realistic, how do we communicate across the gap between the two halves? In order for me to experience what it is like to be a bat, I need to become fully indistinguishable from that of a bat, and at that point I am no longer capable of having human phenomenological experiences. 

To put it bluntly, there is always an information loss when we try to experience something so vastly different than ourselves, there is loss in the analogy that is created to communicate from bat-like experiences into human communicable knowledge of those experiences. When I try to 'bridge the gap', and talk about my bat-experiences, even if replicated fully, I cannot really communicate them. I can only communicate the human-centric analogy of them which degrades them and essentially compresses them into an alternative encoding.

To function properly, Nagel argues that any reductionist program has to be based on an analysis of the things which are going to be reduced. If the reductionist model does not account for conscious experience it is not properly formed. To him, the physical basis of the mind has to account for the specific phenomenological differences in experience between different minds. 

He goes on to claim that we cannot ever describe within our own language or symbols the phenomenology of other minds different from our own. Even with regard to our ability to describe our own minds, he states that we would probably not be able to get an accurate description of our own phenomenology through our linguistic compression if our minds weren’t already basically the same from person to person. By this he means the less similar I am to another person's mind the less likely I am to understand their phenomenological descriptions of their subjective experience.

Next, he discusses how we can move to develop what he claims to be 'objective' models of various things. Our models commonly have components that Nagel argues we can separate out, things that are measurable by things other than the human body, and things that are intrinsic to the human experience of a given object. 

He argues that if we want an objective view of a specific object the best thing we can hope to do is move as far away from our human descriptive experience of that object as possible to be more ‘objective’. The example he gives is potentially using some outside apparatus in order to create objective facts about the world around us that are not centralized within the human experience. 

In the text, the main example he gives is lightning as a human experience and lightening as experienced by some kind of device which measures some aspect of the physical phenomena. In this way, he argues that we can build up sets of facts that transcend the experiences of individuals. 

Near the end of the text, he argues that we could potentially form some kind of new way to communicate experiences but does not go into what this would look like. This could potentially be linguistic or through some technological advance which would allow us to experience the consciousness of another being through an apparatus connecting the two. He does not however give any picture of what this might actually materially look like.


